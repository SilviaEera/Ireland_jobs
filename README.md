# Ireland_jobs
Webscrapper for different job sites  in Ireland.

**1)** For any oparating system you are using you need to install Anaconda Navigator to run the files. 

**2)** For downloading and installing Anaconda on your system you need to go to "https://www.anaconda.com/products/individual" and download and install the desired  version suitable for your oparating system.

**3)** After installation open Anaconda and click on Environment.

**4)** Go to the bottom left of the screen and create a new environment with a name. After creation of the environment click on the triangle( play ) button beside the new environment name and click on open terminal. 

**5)** Install scrapy with "pip install Scrapy" or "pip3 install Scrapy" if it's not already installed on you computer. (Make sure to install it on the environment you will be workinhg in by opening the terminal from the new environment.)  

**6)** To check if you have scrapy installed or not just type scrapy on your command line ( from the anaconda environment ) and if you dont get any errors you have scrapy installed on your system. 

**7)** After that install VS Code on the same environment. (Download VS Code from the official site "https://code.visualstudio.com/download"). So when you open anaconda you can see VS Code on your anaconda with other applications.

**To run the files:**

**8)** Open anaconda navigatort and click on the enviroment you just created. Click on the play buttion and open the terminal from anaconda. 

**9)** cd to the directory where you kept the files you just cloned or downloaded from github.

**10)** To run the scrapy spider files just type   " scrapy crawl spidder_name " and hit enter.

